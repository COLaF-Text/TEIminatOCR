<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>TEIminatOCR, an image to TEI full javascript application</title>
    <script src='http://lovasoa.github.io/tidy-html5/tidy.js'></script>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script src='https://cdn.jsdelivr.net/npm/tesseract.js@5/dist/tesseract.min.js'></script>
    <script src="https://cdn.jsdelivr.net/npm/xml-beautify@1.2.3/dist/XmlBeautify.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <!-- and it's easy to individually load additional languages -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/xml.min.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">
    <style>
      canvas {
          display:block;
          border: 1px solid black;
          margin-top:10px;
      }
    </style>
</head>
<body>
    <div class="container-fluid">
      <div class="row">
        <div class="col-md-10 offset-md-1 mb-2 mt-2">
          <div class="mb-2">
            <h1>Welcome to the TEIminatOCR</h1>
            <p>TEIminatOCR is an application that reuses object identification for segmenting and recognizing zones of texts, OCR using TesseractJS and the Segmonto ontology. Images that you will load will be first segmented through YOLO object detection, then OCRized. Bounding box of lines are then dispatched in each area and the TEI is produced for the output.</p>
            <h3>Bibliography</h3>
            <ul style="font-size:smaller;">
              <li>
                Jocher, G., Chaurasia, A., & Qiu, J. (2023). YOLO by Ultralytics (Version 8.0.0) [Computer software]. <a href="https://github.com/ultralytics/ultralytics">https://github.com/ultralytics/ultralytics</a>
              </li>
              <li>
                Clérice, T. (2023). You Actually Look Twice At it (YALTAi): using an object detection approach instead of region segmentation within the Kraken engine. [Preprint] <a target="_blank" href="https://enc.hal.science/hal-03723208v2">⟨hal-03723208v2⟩</a>
              </li>
              <li>Pinche, A., Gabay, S., Camps, J. B., & Jahan, C. (2022). SegmOnto: Vocabulaire contrôlé pour décrire les manuscrits et les imprimés. In Segmenter et annoter les images: déconstruire pour reconstruire. <i>1st International Workshop on Computational Paleography (IWCP@ICDAR 2021)</i>, Lausanne, Switzerland. <a href="https://hal.science/hal-03336528">⟨hal-03336528⟩</a></li>
              <li>R. Smith. (2007). An Overview of the Tesseract OCR Engine. <i>Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)</i>,, vol. 2, pp. 629–633. <a href="https://doi.org/10.1109/ICDAR.2007.4376991">10.1109/ICDAR.2007.4376991</a>.</li>
              <li>
                Wu, J. (2023). TesseractJS (Version 5.0.2) [Computer software]. <a href="https://github.com/naptha/tesseract.js">https://github.com/naptha/tesseract.js</a>
              </li>
            </ul>
          </div>
          <hr />
          <h3>Form</h3>
          <h4>Choose your input</h4>
          <div class="row mb-2">
            <div class="col-sm-3 col-md-2 offset-md-3 offset-sm-3 col-form-label">
              <div class="form-check">
                <input type="radio" name="use" value="uploadInput" class="form-check-input" id="useUpload" />
                <label for="useUpload" class="form-check-label">Upload an image</label>
              </div>
            </div>
            <div class="col-sm-4 text-start">
              <input type="file" class="form-control" id="uploadInput">
            </div>
          </div>
          <div class="row mb-2">
            <div class="col-sm-3 col-md-2 offset-md-3 offset-sm-3 col-form-label">
              <div class="form-check">
                <input type="radio" name="use" value="urlInput" class="form-check-input" id="useURL" checked/>
                <label for="useURL" class="form-check-label">Use an URL</label>
              </div>
            </div>
            <div class="col-sm-4 text-start">
              <input type="url" class="form-control" id="urlInput" value="https://gallica.bnf.fr/iiif/ark:/12148/bd6t5327037p/f582/full/,1200/0/native.jpg" />
            </div>
          </div>
          <div class="row mb-2">
            <div class="col-sm-3 col-md-2 offset-md-3 offset-sm-3 col-form-label">
              <div class="form-check">
                <input type="radio" name="use" value="camInput" class="form-check-input" id="useCam"/>
                <label for="useCam" class="form-check-label">Use your phone camera</label>
              </div>
            </div>
            <div class="col-sm-4 text-start">
              <input type="file" class="form-control" id="camInput" accept="image/*" capture="user">
            </div>
          </div>

          <div class="row">
            <div class="col-sm-12 text-center">
              <a class="btn btn-primary" id="button" href="#">Process</a>
            </div>
          </div>
          <hr />
        </div>
      </div>
      <div class="row">
        <div class="col-md-5 offset-md-1">
          <canvas id="canva"></canvas>
        </div>
        <div class="col-md-5">
          <pre id="te" style="min-height:400px; width: 100%;"></pre>
        </div>
      </div>
    </div>

    <script>
      class Teiminatocr {
        constructor(
                img_width,
                img_height,
                yolo_min_prob,
                yolo_overlap,
                yolo_model_out_size,
                radio_name,
                textarea_id,
                submit_id,
                canva_id,
                median_word_space_ratio,
                min_ocr_confidence
        ) {
          this.img_width = img_width || 640;
          this.img_height = img_height || 640;
          this.yolo_min_prob = yolo_min_prob || 0.3;
          this.yolo_overlap = yolo_overlap || 0.4;
          this.median_word_space_ratio = median_word_space_ratio || 2;
          this.min_ocr_confidence = min_ocr_confidence || 10;

          // Depends on your model (1, 23, 13125) is the output shape for us with 800*800
          this.yolo_model_out_size = yolo_model_out_size || 8400;

          this.radio_name = radio_name || "use";
          this.textarea = document.getElementById(textarea_id || "te");
          this.button = document.getElementById(submit_id || "button");
          this.canva = document.getElementById(canva_id || "canva");
          this.yolo_classes = [
             "DigitizationArtefactZone", "DropCapitalZone", "GraphicZone", "GraphicZone-Legend",
            "GraphicZone-Maths", "MainZone-Entry", "MainZone-Head", "MainZone-Lg",
            "MainZone-Other", "MainZone-P", "MainZone-Sp", "Mainzone-Other",
            "MarginTextZone-Notes", "NumberingZone", "PageTitleZone", "PageTitleZone-Index",
            "RunningTitleZone", "StampZone", "TableZone", "TableZone-Legend"
          ];
          this.setup_button(this.button);
        }

        formatXml(xml) {
            const PADDING = ' '.repeat(2); // set desired indent size here
            const reg = /(>)(<)(\/*)/g;
            let pad = 0;

            xml = xml.replace(reg, '$1\n$2$3');

            return xml.split('\n').map((node, index) => {
                let indent = 0;
                if (node.match(/.+<\/\w[^>]*>$/)) {
                    indent = 0;
                } else if (node.match(/^<\/\w/) && pad > 0) {
                    pad -= 1;
                } else if (node.match(/^<\w.*\/>/)) {
                    indent = 0;
                } else if (node.match(/^<\w[^>]*[^\/]>.*$/)) {
                    indent = 1;
                } else {
                    indent = 0;
                }

                pad += indent;

                return PADDING.repeat(pad - indent) + node;
            }).join('\n');
        }

        /**
         * Binds the processing function to a button
         * @param button document Node on which to bind the click event.
         */
        setup_button(button) {
          button.addEventListener("click", async(event) => {
            event.preventDefault();
            button.innerText = "Be patient, it's coming";

            // Define input
            const using = this.getMeTheRadio(),
                  input = document.getElementById(using);
            let val = null;

            if (using === "urlInput") {
              val = input.value;
            } else {
              val = input.files[0];
            }

            const out = await this.detect_objects_on_image(val);
            this.textarea.innerHTML = hljs.highlight(
              this.formatXml( // Little hack that does not work
                  "<?xml version=\"1.0\" encoding=\"utf-8\"?>"+out.xml.outerHTML
              ).split("<lb>").join("<lb/>").replace(/<\/lb>/g, ''),
              { language: 'xml' }
            ).value;
            this.draw_image_and_boxes(
              val,
              out.boxes,
              out.lines
            );
            button.innerText = "Process";
         });
        }

        /**
         * Gets the value of the selected radio providing the image.
         *
         * @returns {string} The value of the selected radio button, or null if none is selected.
         */
        getMeTheRadio() {
          const radioButtons = document.getElementsByName(this.radio_name);
          let selectedValue = null;
          for (let i = 0; i < radioButtons.length; i++) {
            if (radioButtons[i].checked) {
              selectedValue = radioButtons[i].value;
              break; // Exit the loop once the checked radio button is found
            }
          }
          return selectedValue;
        }

        /**
         * Function draws the image from provided file
         * and bounding boxes of detected objects on
         * top of the image
         * @param file Uploaded file object
         * @param boxes Array of bounding boxes in format [[x1,y1,x2,y2,object_type,probability],...]
         * @param lines Array of lines objects with bounding boxes in format [[x1,y1,x2,y2], ...]
         */
        draw_image_and_boxes(file, boxes, lines) {
            const img = new Image();

            if ((typeof file === 'string' || file instanceof String) && file.startsWith("http")) {
                img.crossOrigin = 'Anonymous';
                img.crossDomain = true;
                img.src = file;
            } else {
                img.src = URL.createObjectURL(file);
            }
            img.onload = () => {
                const scale = this.textarea.offsetWidth / img.width;
                this.canva.width = this.textarea.offsetWidth;
                this.canva.height = img.height * scale;
                const ctx = this.canva.getContext("2d");
                ctx.imageSmoothingEnabled = false;
                ctx.drawImage(img, 0, 0, this.canva.width, this.canva.height);
                ctx.strokeStyle = "#00FF00";
                ctx.lineWidth = 1;
                ctx.font = "18px serif";
                boxes.forEach(([x1, y1, x2, y2, label]) => {
                    ctx.strokeRect(x1 * scale, y1 * scale, (x2 - x1) * scale, (y2 - y1) * scale);
                    ctx.fillStyle = "#00ff00";
                    ctx.fillText(label, x1 * scale, (y1 + 18) * scale);
                });
                lines.forEach(([x1, y1, x2, y2]) => {
                    ctx.strokeStyle = "#000000";
                    ctx.strokeRect(x1 * scale, y1 * scale, (x2 - x1) * scale, (y2 - y1) * scale);
                });
            }
        }

        /**
         * Function receives an image, passes it through YOLOv8 neural network
         * and returns an array of detected objects and their bounding boxes
         * @param buf Input image body
         * @returns {Object} An object with the following properties:
         *   - `boxes` (Array): An array of bounding boxes in format [[x1,y1,x2,y2,object_type,probability],...].
         *   - `xml` (Node): XML data.
         *   - `lines` (Array): An array of lines represented as arrays of coordinates in the format [x0, y0, x1, y1].
         */
        async detect_objects_on_image(buf) {
          const [img, input, img_width, img_height] = await this.prepare_input(buf);
          const output = await this.run_model(input);
          const lines = (await this.OCRize(img)).map((line) => this.reprocess_lines(line)).flat();
          const boxes = this.process_output(output, img_width, img_height);
          boxes.sort((a, b) => {
            // Compare the second floating-point element (index 1) first
            if (a[1] !== b[1]) {
                return a[1] - b[1];
            } else {
                // If the second elements are equal, compare the first element (index 0)
                return a[0] - b[0];
            }
          });

          // Boxes : x, y, x2, y2, type, prob
          const xml = document.createElement("body");
          const dispatched = this.dispatchElements(lines, boxes);

          // Create the nodes based on tags and fill them with lines
          for (const zone of Object.values(dispatched)) {
            let xpath = "ab";
            if (zone.isOriginal) {
              xpath = zone.metadata[4];
            }
            let zoneObj = this.getTag(xpath);
            for (let i = 0; i < zone.elements.length; i++) {
              zoneObj.elem.innerHTML += "<lb/>" + zone.elements[i].text.trim() + "\r\n";
            }
            xml.appendChild(zoneObj.doc.documentElement);
          }
          return {
            "boxes": boxes,
            "xml": xml,
            "lines": lines.map(this.map_bbox_to_array)
          };
        }

        /**
         * Get the last inserted object key in an object
         * @param obj An object
         * @returns {string} The key of the last inserted item.
         */
        getLastObjectKey(obj) {
          const keys = Object.keys(obj);
          return keys[keys.length - 1];
        }

        xpath_to_xml(str) {
          const tags = str.split("/");
          const local_document = document.implementation.createDocument(null, "", null);
          let last = local_document;
          for (const tag of tags) {
            const [nodeName, ...attributes] = tag.split(/\s/);
            const element = local_document.createElement(nodeName);
            last.appendChild(element);
            if (attributes.length > 0) {
              for (const attributePair of attributes) {
                const [attrName, attrValue] = attributePair.split("=");
                if (attrName && attrValue) {
                  element.setAttribute(attrName, attrValue.replace(/["']/g, ''));
                }
              }
            }
            last = element;
          }
          return {doc: local_document, elem: last}
          //console.log(new XMLSerializer().serializeToString(local_document));
        }

        /**
         * Get the type of node back from the zone
         * @param zone Type of the YOLO class
         * @returns {{doc: Document, elem: Node}} XML Document
         */
        getTag(zone) {
          // Create a new DOMParser
          const mapping = {
            "DigitalArtefactZone": `damage`,
            "DropCapitalZone": `hi rend="dropcapital"`,
            "GraphicZone": `figure`,
            "GraphicZone-Legend": `figure/head`,
            "GraphicZone-Maths": `figure type="maths"`,
            "MainZone-Entry": `div type="entry"/p`,
            "MainZone-Head": `div/head`,
            "MainZone-Lg": `lg`,
            "MainZone-Other": `div type="other"/p`,
            "MainZone-P": `p`,
            "Mainzone-Sp": `sp/p`,
            "MarginTextZone-Notes": `note`,
            "NumberingZone": `fw type="Numbering"`,
            "PageTitleZone": `div type="pagetitle"/p`,
            "PageTitleZone-Index": `div type="index"`,
            "RunnningTitleZone": `fw type="RunningTitle"`,
            "StampZone": `figure type="stamp"`,
            "TableZone": `figure type="table"`,
            "TableZone-Legend": `figure type="table"/head`
          }
          let tag = "ab";
          if (zone in mapping) {
            tag = mapping[zone];
          }
          return this.xpath_to_xml(tag)
        }

        /**
         * Function used to convert input image to tensor,
         * required as an input to YOLOv8 object detection
         * network.
         * @param buf Content of uploaded file
         * @returns Array of pixels
         */
        async prepare_input(buf) {
          return new Promise(resolve => {
              const img = new Image();
              if ((typeof buf === 'string' || buf instanceof String) && buf.startsWith("http")) {
                  img.crossOrigin = 'Anonymous';
                  img.src = buf;
              } else {
                  img.src = URL.createObjectURL(buf);
              }
              img.onload = () => {
                  const [img_width, img_height] = [img.width, img.height]
                  const canvas = document.createElement("canvas");
                  canvas.width = this.img_width;
                  canvas.height = this.img_height;
                  const context = canvas.getContext("2d");
                  context.imageSmoothingEnabled = false;
                  context.drawImage(img, 0, 0, this.img_width, this.img_height);
                  const imgData = context.getImageData(0, 0, this.img_width, this.img_height);
                  const pixels = imgData.data;

                  const red = [],
                      green = [],
                      blue = [];
                  for (let index = 0; index < pixels.length; index += 4) {
                      red.push(pixels[index] / 255.0);
                      green.push(pixels[index + 1] / 255.0);
                      blue.push(pixels[index + 2] / 255.0);
                  }
                  const input = [...red, ...green, ...blue];
                  resolve([img, input, img_width, img_height])
              }
          });
        }

        /**
         * Function used to pass provided input tensor to YOLOv8 neural network and return result
         * @param input Input pixels array
         * @returns Raw output of neural network as a flat array of numbers
         */
        async run_model(input) {
          const model = await ort.InferenceSession.create("model.onnx");
          input = new ort.Tensor(Float32Array.from(input),[1, 3, this.img_width, this.img_height]);
          const outputs = await model.run({images:input});
          return outputs["output0"].data;
        }

        /**
         * Performs OCR (Optical Character Recognition) on an image to extract text lines.
         *
         * @param {Image} img - The image to be processed for text extraction.
         * @param {string} language - The language for OCR
         * @returns {Array[{bbox: {}, words: Array[{bbox:{}, text: String}]}]} An array of line objects containing recognized text lines.
         * @throws {Error} If an error occurs during the OCR process.
         */
        async OCRize(img, language) {
          try {
            // Create a Tesseract worker with the specified language model.
            const worker = await Tesseract.createWorker(language || "fra");

            // Recognize text lines in the provided image.
            const { data: { lines } } = await worker.recognize(img);

            // Terminate the worker to release resources.
            await worker.terminate();

            return lines;
          } catch (error) {
            // Handle and throw any errors that occur during the OCR process.
            throw new Error(`OCR process failed: ${error.message}`);
          }
        }

        /**
         * Calculate the median of an array of numbers.
         *
         * @param {number[]} numbers - An array of numbers.
         * @returns {number} The median of the numbers.
         */
        median(numbers) {
          const sorted = [...numbers].sort();
          const middle = Math.floor(sorted.length / 2);

          if (sorted.length % 2 === 0) {
            return (sorted[middle - 1] + sorted[middle]) / 2;
          } else {
            return sorted[middle];
          }
        }

        /**
         * Processes an object with a `.bbox` property and a `.words` property,
         * splitting and dispatching words objects into new objects when spaces are too large.
         *
         * @param {Object} inputObject - The input object to be processed.
         * @returns {Array[{words, bbox}]} An array of objects, each containing a `.bbox` property and an array of `.words`.
         */
        reprocess_lines(inputObject) {
          // Extract the `.bbox` and `.words` properties from the input object.
          const bbox = inputObject.bbox;
          const words = inputObject.words.filter((word) => word.confidence > this.min_ocr_confidence);

          // Initialize an array to store the processed objects.
          const result = [];

          // Initialize variables to track the current line of words and its bounding box.
          let currentLine = [];
          let currentLineBBox = { ...bbox };

          // Initialize an array to store the space values between words on the horizontal axis.
          const horizontalSpaces = [];
          for (let wordIndex = 1; wordIndex < words.length; wordIndex++) {
            horizontalSpaces.push(words[wordIndex].bbox.x0 - words[wordIndex-1].bbox.x1);
          }

          const medianSpace = this.median(horizontalSpaces);

          // Iterate through the words in the input object.
          for (let wordIndex = 0; wordIndex < words.length; wordIndex++) {
            const word = words[wordIndex],
                  { bbox: wordBBox, text } = word;

            // Calculate the space between the current word and the end of the current line on the horizontal axis.
            let spaceBetweenWords = 0;
            if (wordIndex !== 0) {
              spaceBetweenWords = words[wordIndex].bbox.x0 - words[wordIndex-1].bbox.x1;
            }

            if (spaceBetweenWords > (medianSpace * this.median_word_space_ratio) || spaceBetweenWords > 0.25 * (bbox.x2-bbox.x1)) {
              // The space is too large; start a new line.
              if (currentLine.length > 0) {
                // Push the current line with its bounding box to the result array.
                result.push({
                  bbox: currentLineBBox,
                  words: currentLine,
                });
              }

              // Start a new line with the current word.
              currentLine = [word];
              currentLineBBox = { ...wordBBox };
            } else {
              // Add the word to the current line.
              currentLine.push(word);
              currentLineBBox.x1 = wordBBox.x1; // Update the end of the current line.
              currentLineBBox.y1 = wordBBox.y1;
            }
          }

          // If there are remaining words in the last line, add it to the result.
          if (currentLine.length > 0) {
            result.push({
              bbox: currentLineBBox,
              words: currentLine,
            });
          }

          // Return the processed objects.
          return result.map(
                  (line) => ({
                    "bbox": {
                      "x0": line.words[0].bbox.x0,
                      "y0": line.words[0].bbox.y0,
                      "x1": line.bbox.x1,
                      "y1": line.bbox.y1
                    },
                    "words": line.words,
                    "text": line.words.map(obj => obj.text).join(" ")
                  })
          )
        }

        /**
         * Function used to convert RAW output from YOLOv8 to an array of detected objects.
         * Each object contain the bounding box of this object, the type of object and the probability
         * @param output Raw output of YOLOv8 network
         * @param img_width Width of original image
         * @param img_height Height of original image
         * @returns {Array[]} - Array of detected objects in a format [[x1,y1,x2,y2,object_type,probability],..]
         */
        process_output(output, img_width, img_height) {
            let boxes = [];
            for (let index = 0; index < this.yolo_model_out_size; index++) {

                const [class_id, prob] = [...Array(80).keys()].map(
                        col => [col, output[this.yolo_model_out_size * (col + 4) + index]]
                ).reduce(
                        (accum, item) => item[1] > accum[1] ? item : accum, [0, 0]
                );

                if (prob < this.yolo_min_prob) {
                    continue;
                }
                const label = this.yolo_classes[class_id];
                const xc = output[index];
                const yc = output[this.yolo_model_out_size + index];
                const w = output[2 * this.yolo_model_out_size + index];
                const h = output[3 * this.yolo_model_out_size + index];
                const x1 = (xc - w / 2) / this.img_width * img_width;
                const y1 = (yc - h / 2) / this.img_height * img_height;
                const x2 = (xc + w / 2) / this.img_width * img_width;
                const y2 = (yc + h / 2) / this.img_height * img_height;
                boxes.push([x1, y1, x2, y2, label, prob]);
            }

            boxes = boxes.sort((box1, box2) => box2[5] - box1[5])
            const result = [];
            while (boxes.length > 0) {
                result.push(boxes[0]);
                boxes = boxes.filter(box => this.iou(boxes[0], box) < this.yolo_overlap);
            }
            return result;
        }

        /**
         * Function calculates "Intersection-over-union" coefficient for specified two boxes
         * https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/.
         * @param box1 First box in format: [x1,y1,x2,y2,object_class,probability]
         * @param box2 Second box in format: [x1,y1,x2,y2,object_class,probability]
         * @returns Intersection over union ratio as a float number
         */
        iou(box1,box2) {
            return this.intersection(box1, box2) / this.union(box1, box2);
        }

        /**
         * Function calculates union area of two boxes.
         *     :param box1: First box in format [x1,y1,x2,y2,object_class,probability]
         *     :param box2: Second box in format [x1,y1,x2,y2,object_class,probability]
         *     :return: Area of the boxes union as a float number
         * @param box1 First box in format [x1,y1,x2,y2,object_class,probability]
         * @param box2 Second box in format [x1,y1,x2,y2,object_class,probability]
         * @returns Area of the boxes union as a float number
         */
        union(box1,box2) {
            const [box1_x1,box1_y1,box1_x2,box1_y2] = box1;
            const [box2_x1,box2_y1,box2_x2,box2_y2] = box2;
            const box1_area = (box1_x2-box1_x1)*(box1_y2-box1_y1)
            const box2_area = (box2_x2-box2_x1)*(box2_y2-box2_y1)
            return box1_area + box2_area - this.intersection(box1,box2)
        }

        /**
         * Function calculates intersection area of two boxes
         * @param box1 First box in format [x1,y1,x2,y2,object_class,probability]
         * @param box2 Second box in format [x1,y1,x2,y2,object_class,probability]
         * @returns Area of intersection of the boxes as a float number
         */
        intersection(box1,box2) {
            const [box1_x1,box1_y1,box1_x2,box1_y2] = box1;
            const [box2_x1,box2_y1,box2_x2,box2_y2] = box2;
            const x1 = Math.max(box1_x1,box2_x1);
            const y1 = Math.max(box1_y1,box2_y1);
            const x2 = Math.min(box1_x2,box2_x2);
            const y2 = Math.min(box1_y2,box2_y2);
            return Math.max(0, x2-x1)*Math.max(0, y2-y1)
        }

        /**
         * Given an object with a property bbox, returns an array of X Y
         * @param obj Object with a property box
         * @returns {*[]} Array in format [x1,y1,x2,y2]
         */
        map_bbox_to_array(obj) {
          return [obj.bbox.x0, obj.bbox.y0, obj.bbox.x1, obj.bbox.y1];
        }

        /**
         * Given a list of lines and a list of zones, dispatch lines into zones. For lines without zones, create new one
         * @param lineList List of line from Tesseract
         * @param zoneList List of zones
         * @returns {{}} Object with structure {key: {elements: [lineObj, ...], isOriginal: bool, metadata: zoneObj}}
         */
        dispatchElements(lineList, zoneList) {
          // Create a dictionary to hold the dispatched elements.
          const dispatchDict = {};

          for (const currentLine of lineList) {
              let maxIntersect = 0;
              let targetBbox = null
              let dispatchDictKey = null;
              let currentLineBbox = this.map_bbox_to_array(currentLine);

              // Iterate over the zones and find which zone has the max IOU of all
              for (const currentZone of zoneList) {
                  const intersect = this.intersection(currentLineBbox, currentZone.slice(0, 4));
                  if (intersect > maxIntersect) {
                      maxIntersect = intersect;
                      targetBbox = currentZone;
                      dispatchDictKey = currentZone.slice(0, 4);
                  }
              }

              if (maxIntersect > 0) {
                  // Add the element to the target bbox in the dictionary.
                  if (!dispatchDict[dispatchDictKey]) {
                      dispatchDict[dispatchDictKey] = {
                          elements: [],
                          isOriginal: true,
                          metadata: targetBbox
                      };
                  }
                  dispatchDict[dispatchDictKey].elements.push(currentLine);
              } else {
                  // If there is no intersection, create a new element and mark it as original.
                  let lastKey = this.getLastObjectKey(dispatchDict);
                  if ((lastKey) && !(dispatchDict[lastKey].isOriginal)) {
                      dispatchDict[lastKey].elements.push(currentLine);
                  } else {
                      dispatchDict[currentLineBbox] = {
                          elements: [currentLine],
                          isOriginal: false,
                          metadata: null
                      };
                  }
              }
          }
          return dispatchDict;
        }
      }
      const runner = new Teiminatocr(800, 800, .3, .5, 13125);
    </script>
</body>
</html>
